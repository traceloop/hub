config-example:
  yaml:
providers:
  - key: azure-openai
    type: azure
    api_key: "<your-azure-api-key>"
    resource_name: "<your-resource-name>"
    api_version: "<your-api-version>"
  - key: openai
    type: openai
    api_key: "<your-openai-api-key>"
  - key: bedrock
    type: bedrock
    api_key: ""# Not used for AWS Bedrock
    region: "<your-aws-region>" # like "us-east-1"
    inference_profile_id: "<your-inference-profile-id>" # like "us"
    AWS_ACCESS_KEY_ID: "<your-aws-access-key>"
    AWS_SECRET_ACCESS_KEY: "<your-aws-secret-key>"
    AWS_SESSION_TOKEN: "<your-session-token>"  # Optional

models:
  - key: gpt-4o-openai
    type: gpt-4o
    provider: openai
  - key: gpt-4o-azure
    type: gpt-4o
    provider: azure-openai
    deployment: "<your-deployment>"
  - key: bedrock-model
    # some models are region specific, it is a good idea to get ARN from cross region reference tab
    type: "< model-id or Inference profile ARN or Inference profile ID>"
    provider: bedrock
    model_provider: "anthropic" # can be: ai21, titan, anthropic
    model_version: "v2:0" # optional, defaults to "v1:0"

pipelines:
  - name: default
    type: chat
    plugins:
      - logging:
          level: info
      - tracing:
          endpoint: "https://api.traceloop.com/v1/traces"
          api_key: "<your-traceloop-api-key>"
      - model-router:
          models:
            - gpt-4o-openai
            - gpt-4o-azure
